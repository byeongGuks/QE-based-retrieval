{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repo is currently modified to inference on CPU environment. To implement on GPU, must edit some files from current repository. (Original DPR repo is based on GPU implementation.)\n",
    "\n",
    "1. In file `DPR/conf/dense_retriever.yaml`, change `no_cuda` to `False`.\n",
    "2. Edit `DPR/dense_retriever.py` to add `.cuda()` to lines 83 and 84 with variables `q_ids_batch` and `q_seg_batch`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd DPR\n",
    "!git clone https://github.com/facebookresearch/DPR.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of necessary downloads for inference\n",
    "# %%bash\n",
    "# python dpr/data/download_data.py --resource data.wikipedia_split.psgs_w100\n",
    "# python dpr/data/download_data.py --resource data.retriever.nq\n",
    "# python dpr/data/download_data.py --resource data.retriever.qas.nq\n",
    "# python dpr/data/download_data.py --resource data.retriever_results.nq.single-adv-hn.wikipedia_passages\n",
    "# python dpr/data/download_data.py --resource checkpoint.retriever.single.nq.bert-base-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python dense_retriever.py \\\n",
    "model_file='downloads/checkpoint/retriever/single/nq/bert-base-encoder.cp' \\\n",
    "qa_dataset=nq_test \\\n",
    "out_file='./result_dense_retriever/' \\\n",
    "ctx_datatsets=dpr_wiki \\\n",
    "encoded_ctx_files=\"downloads/data/retriever_results/nq/single-adv-hn/wikipedia_passages_*\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference using EfficientQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more necessary downloads\n",
    "# %%bash\n",
    "# python dpr/data/download_data.py --resource checkpoint.retriever.multiset.bert-base-encoder\n",
    "# python dpr/data/download_data.py --resource checkpoint.reader.nq-single.hf-bert-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/efficientqa/retrieval-based-baselines.git && cd retrieval-based-baselines && pip3 install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference\n",
    "\n",
    "```\n",
    "python3 run_inference.py \\\n",
    "  --qa_file NQ-open.dev.jsonl \\ # data file with questions\n",
    "  --retrieval_type {tfidf|dpr} \\ # which retrieval to use\n",
    "  --db_path ${base_dir}/data/wikipedia_split/{psgs_w100.tsv|psgs_w100_subset.tsv} \\\n",
    "  --tfidf_path ${tfidf_index} \\ # only matters for TFIDF retrieval\n",
    "  --dpr_model_file ${dpr_retrieval_checkpoint} \\ # only matters for dpr retrieval\n",
    "  --dense_index_path ${dpr_index} \\ # only matters for dpr retrieval\n",
    "  --model_file ${reader_checkpoint} \\ # path to the reader checkpoint\n",
    "  --dev_batch_size 8 \\ # 8 is good for one 32gb GPU\n",
    "  --pretrained_model_cfg bert-base-uncased --encoder_model_type hf_bert --do_lower_case \\\n",
    "  --sequence_length 350 --eval_top_docs 10 20 40 50 80 100 \\\n",
    "  --passages_per_question_predict 100 \\ # 100 for TFIDF, 40 for DPR\n",
    "  --prediction_results_file dev_predictions.json # path to save predictions; comparable to the official evaluation script\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_inference.py \\\n",
    "  --qa_file DPR/downloads/data/retriever/qas/nq-test.csv \\\n",
    "  --retrieval_type dpr \\\n",
    "  --db_path DPR/downloads/data/wikipedia_split/psgs_w100.tsv \\\n",
    "  --dpr_model_file DPR/downloads/checkpoint/retriever/multiset/bert-base-encoder.cp \\\n",
    "  --dense_index_path DPR/downloads/indexes/single/nq/full/index.dpr \\\n",
    "  --model_file DPR/downloads/checkpoint/reader/nq-single/hf-bert-base.cp \\\n",
    "  --dev_batch_size 1 \\\n",
    "  --pretrained_model_cfg bert-base-uncased --encoder_model_type hf_bert --do_lower_case \\\n",
    "  --sequence_length 350 --eval_top_docs 10 \\\n",
    "  --passages_per_question_predict 40 \\\n",
    "  --prediction_results_file dev_predictions.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
