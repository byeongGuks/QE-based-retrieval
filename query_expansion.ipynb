{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Language Model list up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1 T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"It can be defined as a permanent and densely settled place with administratively defined boundaries whose members work primarily on non-agricultural tasks. Cities generally have extensive systems for housing, transportation, sanitation, utilities, land use, production of goods, and communication. Their density facilitates interaction between people, government organisations and businesses, sometimes benefiting different parties in the process, such as improving efficiency of goods and service distribution. Historically, city-dwellers have been a small proportion of humanity overall, but following two centuries of unprecedented and rapid urbanization, more than half of the world population now lives in cities, which has had profound consequences for global sustainability.[4][5] Present-day cities usually form the core of larger metropolitan areas and urban areas—creating numerous commuters traveling towards city centres for employment, entertainment, and education. However, in a world of intensifying globalization, all cities are to varying degrees also connected globally beyond these regions. This increased influence means that cities also have significant influences on global issues, such as sustainable development, climate change, and global health. Because of these major influences on global issues, the international community has prioritized investment in sustainable cities through Sustainable Development Goal 11. Due to the efficiency of transportation and the smaller land consumption, dense cities hold the potential to have a smaller ecological footprint per inhabitant than more sparsely populated areas.[6] Therefore, compact cities are often referred to as a crucial element of fighting climate change.[7] However, this concentration can also have significant negative consequences, such as forming urban heat islands, concentrating pollution, and stressing water supplies and other resources. Other important traits of cities besides population include the capital status and relative continued occupation of the city. For example, country capitals such as Beijing, Jakarta, Kuala lumpur, London, Manila, Mexico City, Moscow, Nairobi, New Delhi, Paris, Rome, Athens, Seoul, Singapore, Tokyo, and Washington, D.C. reflect the identity and apex of their respective nations.[8] Some historic capitals, such as Kyoto, Yogyakarta, and Xi'an, maintain their reflection of cultural identity even without modern capital status.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)ve/main/spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 1.15MB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.21k/1.21k [00:00<00:00, 2.73MB/s]\n",
      "/home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "Downloading pytorch_model.bin: 100%|██████████| 2.95G/2.95G [00:52<00:00, 56.4MB/s]\n",
      "Downloading (…)neration_config.json: 100%|██████████| 147/147 [00:00<00:00, 1.08MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voici les principales villes françaises\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-large')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-large')\n",
    "\n",
    "# Define input tex\n",
    "input_text = \"translate english to French : Whar are the major cities in French\"\n",
    "input_text2 = \"translate French to English : Voici les principales villes françaises\"\n",
    "\n",
    "# Tokenize input text\n",
    "input_ids = tokenizer.encode(input_text2, return_tensors='pt')\n",
    "\n",
    "# Generate output\n",
    "outputs = model.generate(input_ids=input_ids, max_length=100)\n",
    "\n",
    "# Decode output\n",
    "output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (4.28.1)\n",
      "Requirement already satisfied: filelock in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from transformers) (2023.5.5)\n",
      "Requirement already satisfied: requests in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from transformers) (2.30.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from requests->transformers) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from requests->transformers) (2023.5.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (66.0.0)\n",
      "Requirement already satisfied: wheel in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from triton==2.0.0->torch) (3.26.3)\n",
      "Requirement already satisfied: lit in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from triton==2.0.0->torch) (16.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece==0.1.91\n",
      "  Downloading sentencepiece-0.1.91.tar.gz (500 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.5/500.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: sentencepiece\n",
      "  Building wheel for sentencepiece (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentencepiece: filename=sentencepiece-0.1.91-cp311-cp311-linux_x86_64.whl size=47909 sha256=d7a8c2a3fe3ad055ff601cdde6cfd3b9affa69a1ee57b816c74f68f81ff98323\n",
      "  Stored in directory: /home/byeongguk/.cache/pip/wheels/e2/3e/74/a1ab1b50618e5f35b324786a393af5140e9a2c091fe1e4266a\n",
      "Successfully built sentencepiece\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.91\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentencepiece==0.1.91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.12.0-cp311-cp311-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.12.0 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.12.0-cp311-cp311-win_amd64.whl (272.9 MB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\dmis\\anaconda3\\envs\\qeretrieval\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.3.3)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting h5py>=2.9.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached h5py-3.8.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "Collecting jax>=0.3.15 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached jax-0.4.8-py3-none-any.whl\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dmis\\anaconda3\\envs\\qeretrieval\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\dmis\\anaconda3\\envs\\qeretrieval\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\dmis\\anaconda3\\envs\\qeretrieval\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\dmis\\anaconda3\\envs\\qeretrieval\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.22.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dmis\\anaconda3\\envs\\qeretrieval\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (67.7.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dmis\\anaconda3\\envs\\qeretrieval\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dmis\\anaconda3\\envs\\qeretrieval\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dmis\\anaconda3\\envs\\qeretrieval\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\dmis\\anaconda3\\envs\\qeretrieval\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached grpcio-1.54.0-cp311-cp311-win_amd64.whl (4.1 MB)\n",
      "Collecting tensorboard<2.13,>=2.12 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\dmis\\anaconda3\\envs\\qeretrieval\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Collecting keras<2.13,>=2.12.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\dmis\\anaconda3\\envs\\qeretrieval\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dmis\\anaconda3\\envs\\qeretrieval\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.40.0)\n",
      "Collecting ml-dtypes>=0.0.3 (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached ml_dtypes-0.1.0-cp311-cp311-win_amd64.whl (120 kB)\n",
      "Collecting scipy>=1.7 (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached scipy-1.10.1-cp311-cp311-win_amd64.whl (42.2 MB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dmis\\anaconda3\\envs\\qeretrieval\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.29.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dmis\\anaconda3\\envs\\qeretrieval\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dmis\\anaconda3\\envs\\qeretrieval\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.3.3)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dmis\\anaconda3\\envs\\qeretrieval\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dmis\\anaconda3\\envs\\qeretrieval\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dmis\\anaconda3\\envs\\qeretrieval\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dmis\\anaconda3\\envs\\qeretrieval\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dmis\\anaconda3\\envs\\qeretrieval\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\dmis\\anaconda3\\envs\\qeretrieval\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dmis\\anaconda3\\envs\\qeretrieval\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: scipy, rsa, pyasn1-modules, opt-einsum, ml-dtypes, markdown, keras, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, jax, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 gast-0.4.0 google-auth-2.17.3 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.54.0 h5py-3.8.0 jax-0.4.8 keras-2.12.0 markdown-3.4.3 ml-dtypes-0.1.0 opt-einsum-3.3.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 scipy-1.10.1 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-intel-2.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2 GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Q: Roger has 5 tennis balls. He buys 2 more cans of\n",
    "tennis balls. Each can has 3 tennis balls. How many\n",
    "tennis balls does he have now?\n",
    "A: Roger started with 5 balls. 2 cans of 3 tennis balls\n",
    "each is 6 tennis balls. 5 + 6 = 11. The answer is 11.\n",
    "Q: The cafeteria had 23 apples. If they used 20 to\n",
    "make lunch and bought 6 more, how many apples\n",
    "do they have?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptQE = \"\"\"\n",
    "Q: Who is the best soccer player?\n",
    "A: best soccer player mean the player who score many goal in game. So Who is the best soccer player?\n",
    "Q: What are the major cities in france?\n",
    "A: \n",
    "\"\"\"\n",
    "\n",
    "promptQE = \"\"\"\n",
    "Expand Following Query with various terms\n",
    "What are the major cities in france?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.50MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 88.0MB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 665/665 [00:00<00:00, 2.68MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 548M/548M [00:11<00:00, 47.9MB/s] \n",
      "Downloading (…)neration_config.json: 100%|██████████| 124/124 [00:00<00:00, 633kB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Generate text\n",
    "input_text = \"What are the major cities in france?\"\n",
    "input_ids = tokenizer.encode(\"hello\", return_tensors='pt')\n",
    "attention_mask = torch.ones(input_ids.shape, dtype=torch.long)\n",
    "output = model.generate(input_ids, max_length=512, attention_mask=attention_mask, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "# Decode the output\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.50MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 875kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 689/689 [00:00<?, ?B/s] \n",
      "Downloading pytorch_model.bin: 100%|██████████| 6.43G/6.43G [01:46<00:00, 60.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')\n",
    "model = GPT2Model.from_pretrained('gpt2-xl')\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"\\nExpand Following Query with various terms\\nWhat are the major cities in france?\\nTo get information from the query you must use a string in bold type as shown in the example under The Result:\\nFrom the query: 'Cities in France\\nOr you can choose this query result by clicking the 'Expand Following Query' from the right hand column.\\nHow does it work?\\nIn a nutshell, the idea behind the Expand Following Query is that after typing your query you\"},\n",
       " {'generated_text': '\\nExpand Following Query with various terms\\nWhat are the major cities in france?\\nExpand Following Query with various terms\\nExpand What is the weather like in the city of lyon?\\nExpand \"what do you call the people that live in France\"\\nLoan terms for the French countryside\\nExpand Please select a region (Lausanne, Nice, Marseille, Toulouse, etc)\\nPlease select a type of loan from this drop-down menu'},\n",
       " {'generated_text': '\\nExpand Following Query with various terms\\nWhat are the major cities in france?\\nFrance is very famous for its varied architecture and cities. Many of these cities were built on old ruins that have been gradually reorganized into new districts in the past.\\nBelow, it shows the major cities in the world.'},\n",
       " {'generated_text': '\\nExpand Following Query with various terms\\nWhat are the major cities in france?\\nFACT: France has 8 of the largest cities, including Paris and Marseille, which are both large. France has 7 different regions:\\nFrançois Mitterrand\\nExpand \"The best food in the world\"\\nWho is the current president of france?\\nFACT: Hollande was elected in 2012, he is also currently the Socialist Party\\'s candidate for the 2016 presidential elections,'},\n",
       " {'generated_text': \"\\nExpand Following Query with various terms\\nWhat are the major cities in france?\\nIn case you need a map of any major city for a particular date/time in a year, just enter the town, city or region (if there is several, just put them all in), and we will give you all the important details for this date:\\nEntering information like this is very quick and easy. You only get one picture or even text message. It's easier to read and\"}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2-xl')\n",
    "set_seed(42)\n",
    "generator(promptQE, max_length=100, num_return_sequences=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the major cities in france?,"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3 LLama  (need facebook license)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaModel, LlamaConfig\n",
    "\n",
    "configuration = LlamaConfig()\n",
    "model = LlamaModel(configuration)\n",
    "configuration = model.config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4 pyllama https://github.com/juncongmoo/pyllama"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-5 MPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\n",
      "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: einops\n",
      "Successfully installed einops-0.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install einops\n",
    "%pip install flash-attn==1.0.3.post0\n",
    "%pip install triton==2.0.0.dev20221202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (66.0.0)\n",
      "Requirement already satisfied: wheel in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from triton==2.0.0->torch) (3.26.3)\n",
      "Requirement already satisfied: lit in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from triton==2.0.0->torch) (16.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.23k/1.23k [00:00<00:00, 4.91MB/s]\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Downloading (…)configuration_mpt.py: 100%|██████████| 9.08k/9.08k [00:00<00:00, 23.6MB/s]\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Downloading (…)main/modeling_mpt.py: 100%|██████████| 17.4k/17.4k [00:00<00:00, 61.3MB/s]\n",
      "Downloading (…)ve/main/attention.py: 100%|██████████| 16.1k/16.1k [00:00<00:00, 40.4MB/s]\n",
      "Downloading (…)resolve/main/norm.py: 100%|██████████| 2.56k/2.56k [00:00<00:00, 16.3MB/s]\n",
      "Downloading (…)solve/main/blocks.py: 100%|██████████| 2.49k/2.49k [00:00<00:00, 18.0MB/s]\n",
      "Downloading (…)meta_init_context.py: 100%|██████████| 3.64k/3.64k [00:00<00:00, 22.0MB/s]\n",
      "Downloading (…)refixlm_converter.py: 100%|██████████| 27.2k/27.2k [00:00<00:00, 60.1MB/s]\n",
      "Downloading (…)in/param_init_fns.py: 100%|██████████| 12.6k/12.6k [00:00<00:00, 31.1MB/s]\n",
      "Downloading (…)n/adapt_tokenizer.py: 100%|██████████| 1.75k/1.75k [00:00<00:00, 10.9MB/s]\n",
      "Downloading (…)model.bin.index.json: 100%|██████████| 16.0k/16.0k [00:00<00:00, 46.0MB/s]\n",
      "Downloading (…)l-00001-of-00002.bin: 100%|██████████| 9.94G/9.94G [03:05<00:00, 53.6MB/s]\n",
      "Downloading (…)l-00002-of-00002.bin: 100%|██████████| 3.36G/3.36G [00:58<00:00, 57.4MB/s]\n",
      "Downloading shards: 100%|██████████| 2/2 [04:04<00:00, 122.29s/it]\n",
      "/home/byeongguk/.cache/huggingface/modules/transformers_modules/mosaicml/mpt-7b-instruct/bd1748ec173f1c43e11f1973fc6e61cb3de0f327/attention.py:144: UserWarning: While `attn_impl: triton` can be faster than `attn_impl: flash` it uses more memory. When training larger models this can trigger alloc retries which hurts performance. If encountered, we recommend using `attn_impl: flash` if your model does not use `alibi` or `prefix_lm`.\n",
      "  warnings.warn('While `attn_impl: triton` can be faster than `attn_impl: flash` ' + 'it uses more memory. When training larger models this can trigger ' + 'alloc retries which hurts performance. If encountered, we recommend ' + 'using `attn_impl: flash` if your model does not use `alibi` or `prefix_lm`.')\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.57s/it]\n",
      "Downloading (…)neration_config.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 723kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MPTForCausalLM(\n",
       "  (transformer): MPTModel(\n",
       "    (wte): Embedding(50432, 4096)\n",
       "    (emb_drop): Dropout(p=0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (1): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (2): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (3): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (4): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (5): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (6): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (7): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (8): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (9): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (10): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (11): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (12): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (13): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (14): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (15): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (16): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (17): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (18): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (19): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (20): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (21): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (22): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (23): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (24): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (25): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (26): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (27): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (28): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (29): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (30): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (31): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm_f): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "\n",
    "config = transformers.AutoConfig.from_pretrained(\n",
    "  'mosaicml/mpt-7b-instruct',\n",
    "  trust_remote_code=True\n",
    ")\n",
    "config.attn_config['attn_impl'] = 'triton'\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "  'mosaicml/mpt-7b-instruct',\n",
    "  config=config,\n",
    "  torch_dtype=torch.bfloat16,\n",
    "  trust_remote_code=True\n",
    ")\n",
    "model.to(device='cuda:6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 187,   50,   27, 1737,  403,  253, 2201, 8238,  275, 1315,  593,   32,\n",
       "          187,   34,   27, 2490]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promptQE = \"\"\"\n",
    "Q: What are the major cities in france?\n",
    "A: \n",
    "\"\"\"\n",
    "\n",
    "encoded_input = tokenizer(promptQE, return_tensors='pt')\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = encoded_input['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = input_ids.to(device='cuda:6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = encoded_input.to(device='cuda:6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/byeongguk/.conda/envs/qeRetrieval/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict, Tuple\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import (\n",
    "    StoppingCriteria,\n",
    "    StoppingCriteriaList,\n",
    "    TextIteratorStreamer,\n",
    ")\n",
    "\n",
    "\n",
    "INSTRUCTION_KEY = \"### Instruction:\"\n",
    "RESPONSE_KEY = \"### Response:\"\n",
    "END_KEY = \"### End\"\n",
    "INTRO_BLURB = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
    "PROMPT_FOR_GENERATION_FORMAT = \"\"\"{intro}\n",
    "{instruction_key}\n",
    "{instruction}\n",
    "{response_key}\n",
    "\"\"\".format(\n",
    "    intro=INTRO_BLURB,\n",
    "    instruction_key=INSTRUCTION_KEY,\n",
    "    instruction=\"{instruction}\",\n",
    "    response_key=RESPONSE_KEY,\n",
    ")\n",
    "\n",
    "\n",
    "class InstructionTextGenerationPipeline:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        trust_remote_code=True,\n",
    "        use_auth_token=None,\n",
    "    ) -> None:\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch_dtype,\n",
    "            trust_remote_code=trust_remote_code,\n",
    "            use_auth_token=use_auth_token,\n",
    "        )\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_name,\n",
    "            trust_remote_code=trust_remote_code,\n",
    "            use_auth_token=use_auth_token,\n",
    "        )\n",
    "        if tokenizer.pad_token_id is None:\n",
    "            warnings.warn(\n",
    "                \"pad_token_id is not set for the tokenizer. Using eos_token_id as pad_token_id.\"\n",
    "            )\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "        tokenizer.padding_side = \"left\"\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.eval()\n",
    "        self.model.to(device=device, dtype=torch_dtype)\n",
    "\n",
    "        self.generate_kwargs = {\n",
    "            \"temperature\": 0.1,\n",
    "            \"top_p\": 0.92,\n",
    "            \"top_k\": 0,\n",
    "            \"max_new_tokens\": 1024,\n",
    "            \"use_cache\": True,\n",
    "            \"do_sample\": True,\n",
    "            \"eos_token_id\": self.tokenizer.eos_token_id,\n",
    "            \"pad_token_id\": self.tokenizer.pad_token_id,\n",
    "            \"repetition_penalty\": 1.1,  # 1.0 means no penalty, > 1.0 means penalty, 1.2 from CTRL paper\n",
    "        }\n",
    "\n",
    "    def format_instruction(self, instruction):\n",
    "        return PROMPT_FOR_GENERATION_FORMAT.format(instruction=instruction)\n",
    "\n",
    "    def __call__(\n",
    "        self, instruction: str, **generate_kwargs: Dict[str, Any]\n",
    "    ) -> Tuple[str, str, float]:\n",
    "        s = PROMPT_FOR_GENERATION_FORMAT.format(instruction=instruction)\n",
    "        input_ids = self.tokenizer(s, return_tensors=\"pt\").input_ids\n",
    "        input_ids = input_ids.to(self.model.device)\n",
    "        gkw = {**self.generate_kwargs, **generate_kwargs}\n",
    "        with torch.no_grad():\n",
    "            output_ids = self.model.generate(input_ids, **gkw)\n",
    "        # Slice the output_ids tensor to get only new tokens\n",
    "        new_tokens = output_ids[0, len(input_ids[0]) :]\n",
    "        output_text = self.tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "        return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "/home/byeongguk/.cache/huggingface/modules/transformers_modules/mosaicml/mpt-7b-instruct/bd1748ec173f1c43e11f1973fc6e61cb3de0f327/attention.py:148: UserWarning: Using `attn_impl: torch`. If your model does not use `alibi` or `prefix_lm` we recommend using `attn_impl: flash` otherwise we recommend using `attn_impl: triton`.\n",
      "  warnings.warn('Using `attn_impl: torch`. If your model does not use `alibi` or ' + '`prefix_lm` we recommend using `attn_impl: flash` otherwise ' + 'we recommend using `attn_impl: triton`.')\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.31s/it]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 237/237 [00:00<00:00, 1.82MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 2.11M/2.11M [00:00<00:00, 2.39MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 99.0/99.0 [00:00<00:00, 545kB/s]\n",
      "/tmp/ipykernel_199271/1000956575.py:50: UserWarning: pad_token_id is not set for the tokenizer. Using eos_token_id as pad_token_id.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "generate = InstructionTextGenerationPipeline(\n",
    "    \"mosaicml/mpt-7b-instruct\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "stop_token_ids = generate.tokenizer.convert_tokens_to_ids([\"<|endoftext|>\"])\n",
    "\n",
    "\n",
    "# Define a custom stopping criteria\n",
    "class StopOnTokens(StoppingCriteria):\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        for stop_id in stop_token_ids:\n",
    "            if input_ids[0][-1] == stop_id:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import textwrap\n",
    "\n",
    "def get_prompt(instruction):\n",
    "    prompt_template = f\"Expansion Following Query with various term. \\n\\n\\n{instruction}\\n\\n###\"\n",
    "    return prompt_template\n",
    "\n",
    "# print(get_prompt('What is the meaning of life?'))\n",
    "\n",
    "def parse_text(text):\n",
    "        wrapped_text = textwrap.fill(text, width=100)\n",
    "        print(wrapped_text +'\\n\\n')\n",
    "        # return assistant_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest city and capital of France, Paris has over 2 million inhabitants within its\n",
      "administrative limits on the Seine River. It's one of Europe’s leading tourist destinations with\n",
      "more than 30 million visitors each year. The city hosts many museums including the Louvre Museum\n",
      "which contains some of the world’s most famous artworks such as Mona Lisa by Leonardo da Vinci or\n",
      "Venus de Milo from ancient Greece. Other popular attractions include Notre Dame Cathedral (the\n",
      "largest Gothic cathedral), Eiffel Tower (one of the tallest structures in Paris) and Sacré-Cœur\n",
      "Basilica (an iconic landmark).\n",
      "\n",
      "\n",
      "CPU times: user 2.69 s, sys: 29 ms, total: 2.72 s\n",
      "Wall time: 2.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = 'What are the major cities in France?'\n",
    "generated_text = generate(prompt)\n",
    "parse_text(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qeRetrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
